{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Imports and requirements\n",
    "\n",
    "* В данном соревновании мы имеем дело с последовательностями, один из интуитивных способов работы с ними - использование рекуррентных сетей. Данный бейзлайн посвящен тому, чтобы показать, как можно строить хорошие решения без использования сложного и трудоемкого feature engineering-а (чтобы эффективно решать ту же задачу с высоким качеством с помощью бустингов нужно несколько тысяч признаков), благодаря рекуррентным сетям. В этом ноутбуке мы построим решение с использованием фреймфорка `tensorflow`. Для комфортной работы Вам понадобится машина с `GPU` (хватит ресурсов `google colab` или `kaggle`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import config\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# добавим корневую папку, в ней лежат все необходимые полезные функции для обработки данных\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* В базовом решении на нейронных сетях приведена вся обработка данных и все стадии препроцесснга. В данном ноутбуке опустим данный раздел и используем уже готовые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TRANSACTIONS_PATH = '/media/DATA/AlfaBattle/train_transactions_contest/'\n",
    "TEST_TRANSACTIONS_PATH = '/media/DATA/AlfaBattle/test_transactions_contest/'\n",
    "\n",
    "TRAIN_TARGET_PATH = '/media/DATA/AlfaBattle/train_target.csv'\n",
    "PRE_TRANSACTIONS_PATH = '/media/DATA/AlfaBattle//preprocessed_transactions/'\n",
    "PRE_TEST_TRANSACTIONS_PATH = '/media/DATA/AlfaBattle/preprocessed_test_transactions/'\n",
    "PICKLE_VAL_BUCKET_PATH = '/media/DATA/AlfaBattle/val_buckets/'\n",
    "PICKLE_VAL_TRAIN_BUCKET_PATH = '/media/DATA/AlfaBattle/val_train_buckets/'\n",
    "PICKLE_VAL_TEST_BUCKET_PATH = '/media/DATA/AlfaBattle/val_test_buckets/'\n",
    "CHECKPOINTS_ADV_PATH = '/media/DATA/AlfaBattle/checkpoints/tf_advanced_baseline/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/media/DATA/AlfaBattle/val_buckets/processed_chunk_000.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_001.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_002.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_003.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_004.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_005.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_006.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_007.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_008.pkl',\n",
       " '/media/DATA/AlfaBattle/val_buckets/processed_chunk_009.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "path_to_dataset = PICKLE_VAL_BUCKET_PATH\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_val = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_000.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_001.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_002.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_003.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_004.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_005.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_006.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_007.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_008.pkl',\n",
       " '/media/DATA/AlfaBattle/val_train_buckets/processed_chunk_009.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "path_to_dataset = PICKLE_VAL_TRAIN_BUCKET_PATH\n",
    "dir_with_datasets = os.listdir(path_to_dataset)\n",
    "dataset_train = sorted([os.path.join(path_to_dataset, x) for x in dir_with_datasets])\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для создания модели будем использовать фреймворк `tensorflow`. В нем есть все, чтобы писать произвольные сложные архитектуры и быстро эксперементировать.\n",
    "\n",
    "* В бейзлайне мы предлагаем базовые компоненты, чтобы можно было обучать нейронную сеть и отслеживать ее качество. Для этого вам предоставлены следующие функции:\n",
    "    * `data_generators.batches_generator` - функция-генератор, итеративно возвращает батчи, поддерживает батчи для `tensorflow.keras` и `torch.nn.module` моделей. В зависимости от флага `is_train` может быть использована для генерации батчей на train/val/test стадию.\n",
    "    * функция `tf_training.train_epoch` - обучает модель одну эпоху.\n",
    "    * функция `tf_training.eval_model` - проверяет качество модели на отложенной выборке и возвращает roc_auc_score.\n",
    "    * функция `tf_training.inference` - делает предикты на новых данных и готовит фрейм для проверяющей системы.\n",
    "    * класс `training_aux.EarlyStopping` - реализует early_stopping, сохраняя лучшую модель. Совместим с `tensorflow/torch`. Пример использования приведен ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import batches_generator, transaction_features\n",
    "from tf_training import train_epoch, eval_model, inference\n",
    "from training_aux import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все признаки в нашей модели будут категориальными. Для их представления в модели используем категориальные эмбеддинги. Для этого нужно каждому категориальному признаку задать размерность латентного пространства. Используем [формулу](https://forums.fast.ai/t/size-of-embedding-for-categorical-variables/42608) из библиотеки `fast.ai`. Все отображения хранятся в файле `embedding_projections.pkl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../constants/embedding_projections.pkl', 'rb') as f:\n",
    "    embedding_projections = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Реализуем модель. Все входные признаки представим в виде эмбеддингов, сконкатенируем, чтобы получить векторное представление транзакции. Используем SpatialDropout, чтобы регуляризовать эмбеддинги. Подадим последовательности в `BiGRU` рекуррентную сеть. Используем все скрытые состояния сети, чтобы получить агрегированное представление об истории транзакции - пропустим все скрытые состояния `BiGRU` через `AvgPooling` и черерз `MaxPooling`. Представим признак `product` в виде отдельного эмбеддинга. Сконкатенируем его с результатами пулингов. На основе такого входа построим небольшой `MLP`, выступающий классификатором для целевой задачи. Используем градиентный спуск, чтобы решить оптимизационную задачу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transactions_rnn(transactions_cat_features, embedding_projections, product_col_name='product', \n",
    "                          rnn_units=128, classifier_units=32, optimizer=None):\n",
    "    if not optimizer:\n",
    "        optimizer = keras.optimizers.Adam(lr=1e-3)\n",
    "        \n",
    "    inputs = []\n",
    "    cat_embeds = []\n",
    "    \n",
    "    for feature_name in transactions_cat_features:\n",
    "        inp = L.Input(shape=(None, ), dtype='uint32', name=f'input_{feature_name}')\n",
    "        inputs.append(inp)\n",
    "        source_size, projection = embedding_projections[feature_name]\n",
    "        emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_{feature_name}')(inp)\n",
    "        cat_embeds.append(emb)\n",
    "    \n",
    "    # product feature\n",
    "    inp = L.Input(shape=(1, ), dtype='uint32', name=f'input_product')\n",
    "    inputs.append(inp)\n",
    "    source_size, projection = embedding_projections['product']\n",
    "    product_emb = L.Embedding(source_size+1, projection, trainable=True, mask_zero=False, name=f'embedding_product')(inp)\n",
    "    product_emb_reshape = L.Reshape((projection, ))(product_emb)\n",
    "    \n",
    "    concated_cat_embeds = L.concatenate(cat_embeds)\n",
    "    \n",
    "    dropout_embeds = L.SpatialDropout1D(0.05)(concated_cat_embeds)\n",
    " \n",
    "    sequences = L.Bidirectional(L.GRU(units=rnn_units, return_sequences=True))(dropout_embeds)\n",
    "    \n",
    "    pooled_avg_sequences = L.GlobalAveragePooling1D()(sequences)\n",
    "    pooled_max_sequences = L.GlobalMaxPooling1D()(sequences)\n",
    "    \n",
    "    #add dropout=0.5\n",
    "    concated = L.concatenate([pooled_avg_sequences, pooled_max_sequences, product_emb_reshape])\n",
    "    \n",
    "    dense_intermediate = L.Dense(classifier_units, activation='relu', \n",
    "                                 kernel_regularizer=keras.regularizers.L1L2(1e-7, 1e-5))(concated)\n",
    "    \n",
    "    proba = L.Dense(1, activation='sigmoid')(dense_intermediate)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=proba)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "! rm -r {CHECKPOINTS_ADV_PATH}\n",
    "! mkdir {CHECKPOINTS_ADV_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для того, чтобы детектировать переобучение используем EarlyStopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_checkpoints = CHECKPOINTS_ADV_PATH\n",
    "es = EarlyStopping(patience=3, mode='max', verbose=True, save_path=os.path.join(path_to_checkpoints, 'best_checkpoint.pt'), \n",
    "                   metric_name='ROC-AUC', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "train_batch_size = 128\n",
    "val_batch_szie = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_transactions_rnn(transaction_features, embedding_projections, classifier_units=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_currency (InputLayer)     [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_operation_kind (InputLaye [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_card_type (InputLayer)    [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_operation_type (InputLaye [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_operation_type_group (Inp [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_ecommerce_flag (InputLaye [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_payment_system (InputLaye [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_income_flag (InputLayer)  [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_mcc (InputLayer)          [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_country (InputLayer)      [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_city (InputLayer)         [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_mcc_category (InputLayer) [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_day_of_week (InputLayer)  [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_hour (InputLayer)         [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_weekofyear (InputLayer)   [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_amnt (InputLayer)         [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_days_before (InputLayer)  [(None, None)]       0                                            \n__________________________________________________________________________________________________\ninput_hour_diff (InputLayer)    [(None, None)]       0                                            \n__________________________________________________________________________________________________\nembedding_currency (Embedding)  (None, None, 6)      72          input_currency[0][0]             \n__________________________________________________________________________________________________\nembedding_operation_kind (Embed (None, None, 5)      40          input_operation_kind[0][0]       \n__________________________________________________________________________________________________\nembedding_card_type (Embedding) (None, None, 29)     5104        input_card_type[0][0]            \n__________________________________________________________________________________________________\nembedding_operation_type (Embed (None, None, 9)      207         input_operation_type[0][0]       \n__________________________________________________________________________________________________\nembedding_operation_type_group  (None, None, 3)      15          input_operation_type_group[0][0] \n__________________________________________________________________________________________________\nembedding_ecommerce_flag (Embed (None, None, 3)      12          input_ecommerce_flag[0][0]       \n__________________________________________________________________________________________________\nembedding_payment_system (Embed (None, None, 5)      40          input_payment_system[0][0]       \n__________________________________________________________________________________________________\nembedding_income_flag (Embeddin (None, None, 3)      12          input_income_flag[0][0]          \n__________________________________________________________________________________________________\nembedding_mcc (Embedding)       (None, None, 22)     2398        input_mcc[0][0]                  \n__________________________________________________________________________________________________\nembedding_country (Embedding)   (None, None, 9)      225         input_country[0][0]              \n__________________________________________________________________________________________________\nembedding_city (Embedding)      (None, None, 28)     4592        input_city[0][0]                 \n__________________________________________________________________________________________________\nembedding_mcc_category (Embeddi (None, None, 10)     290         input_mcc_category[0][0]         \n__________________________________________________________________________________________________\nembedding_day_of_week (Embeddin (None, None, 5)      40          input_day_of_week[0][0]          \n__________________________________________________________________________________________________\nembedding_hour (Embedding)      (None, None, 9)      225         input_hour[0][0]                 \n__________________________________________________________________________________________________\nembedding_weekofyear (Embedding (None, None, 15)     810         input_weekofyear[0][0]           \n__________________________________________________________________________________________________\nembedding_amnt (Embedding)      (None, None, 6)      66          input_amnt[0][0]                 \n__________________________________________________________________________________________________\nembedding_days_before (Embeddin (None, None, 9)      216         input_days_before[0][0]          \n__________________________________________________________________________________________________\nembedding_hour_diff (Embedding) (None, None, 6)      66          input_hour_diff[0][0]            \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, None, 182)    0           embedding_currency[0][0]         \n                                                                 embedding_operation_kind[0][0]   \n                                                                 embedding_card_type[0][0]        \n                                                                 embedding_operation_type[0][0]   \n                                                                 embedding_operation_type_group[0]\n                                                                 embedding_ecommerce_flag[0][0]   \n                                                                 embedding_payment_system[0][0]   \n                                                                 embedding_income_flag[0][0]      \n                                                                 embedding_mcc[0][0]              \n                                                                 embedding_country[0][0]          \n                                                                 embedding_city[0][0]             \n                                                                 embedding_mcc_category[0][0]     \n                                                                 embedding_day_of_week[0][0]      \n                                                                 embedding_hour[0][0]             \n                                                                 embedding_weekofyear[0][0]       \n                                                                 embedding_amnt[0][0]             \n                                                                 embedding_days_before[0][0]      \n                                                                 embedding_hour_diff[0][0]        \n__________________________________________________________________________________________________\nspatial_dropout1d (SpatialDropo (None, None, 182)    0           concatenate_1[0][0]              \n__________________________________________________________________________________________________\ninput_product (InputLayer)      [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   (None, None, 256)    239616      spatial_dropout1d[0][0]          \n__________________________________________________________________________________________________\nembedding_product (Embedding)   (None, 1, 4)         24          input_product[0][0]              \n__________________________________________________________________________________________________\nglobal_average_pooling1d (Globa (None, 256)          0           bidirectional[0][0]              \n__________________________________________________________________________________________________\nglobal_max_pooling1d (GlobalMax (None, 256)          0           bidirectional[0][0]              \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 4)            0           embedding_product[0][0]          \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 516)          0           global_average_pooling1d[0][0]   \n                                                                 global_max_pooling1d[0][0]       \n                                                                 reshape_1[0][0]                  \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 128)          66176       concatenate_2[0][0]              \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            129         dense[0][0]                      \n==================================================================================================\nTotal params: 320,375\nTrainable params: 320,375\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Запустим цикл обучения, каждую эпоху будем логировать лосс, а так же roc-auc на валидации и на обучении. Будем сохрнаять веса после каждой эпохи, а так же лучшие с помощью early_stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Starting epoch 1\n",
      " 747/7270 [==>...........................] - ETA: 3:46 - loss: 0.1350"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-88f34d3a8b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Starting epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     train_epoch(model, dataset_train, batch_size=train_batch_size, shuffle=True, cur_epoch=epoch, \n\u001b[0m\u001b[1;32m      4\u001b[0m                 steps_per_epoch=7270) #7270\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/AlfaBattle20/rnn_baseline/tf_training.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataset_train, batch_size, shuffle, cur_epoch, steps_per_epoch, callbacks)\u001b[0m\n\u001b[1;32m     21\u001b[0m     train_generator = batches_generator(dataset_train, batch_size=batch_size, shuffle=shuffle,\n\u001b[1;32m     22\u001b[0m                                         output_format='tf', is_train=True)\n\u001b[0;32m---> 23\u001b[0;31m     model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cur_epoch + 1,\n\u001b[0m\u001b[1;32m     24\u001b[0m               initial_epoch=cur_epoch, callbacks=callbacks)\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-rtx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 _r=1):\n\u001b[1;32m   1134\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-rtx/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-rtx/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    823\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-rtx/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2969\u001b[0m       (graph_function,\n\u001b[1;32m   2970\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2971\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2972\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-rtx/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1945\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1946\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1948\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1949\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/tf-rtx/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    554\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    557\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf-rtx/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "    train_epoch(model, dataset_train, batch_size=train_batch_size, shuffle=True, cur_epoch=epoch, \n",
    "                steps_per_epoch=7270) #7270\n",
    "    \n",
    "    val_roc_auc = eval_model(model, dataset_val, batch_size=val_batch_szie)\n",
    "    model.save_weights(os.path.join(path_to_checkpoints, f'epoch_{epoch+1}_val_{val_roc_auc:.3f}.hdf5'))\n",
    "    \n",
    "    es(val_roc_auc, model)\n",
    "    \n",
    "    train_roc_auc = eval_model(model, dataset_train, batch_size=val_batch_szie)\n",
    "    print(f'Epoch {epoch+1} completed. Train roc-auc: {train_roc_auc}, Val roc-auc: {val_roc_auc}')\n",
    "    \n",
    "    if es.early_stop:\n",
    "        print('Early stopping reached. Stop training...')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Все готово, чтобы сделать предсказания для тестовой выборки. Нужно только подготовить данные в том же формате, как и для train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    app_id  product\n",
       "0  1063620        0\n",
       "1  1063621        0\n",
       "2  1063622        1\n",
       "3  1063623        1\n",
       "4  1063624        2"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>app_id</th>\n      <th>product</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1063620</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1063621</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1063622</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1063623</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1063624</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "test_frame = pd.read_csv('/media/DATA/AlfaBattle/test_target_contest.csv')\n",
    "test_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['/media/DATA/AlfaBattle/val_test_buckets/processed_chunk_000.pkl',\n",
       " '/media/DATA/AlfaBattle/val_test_buckets/processed_chunk_001.pkl',\n",
       " '/media/DATA/AlfaBattle/val_test_buckets/processed_chunk_002.pkl',\n",
       " '/media/DATA/AlfaBattle/val_test_buckets/processed_chunk_003.pkl',\n",
       " '/media/DATA/AlfaBattle/val_test_buckets/processed_chunk_004.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "path_to_test_dataset = PICKLE_VAL_TEST_BUCKET_PATH\n",
    "dir_with_test_datasets = os.listdir(path_to_test_dataset)\n",
    "dataset_test = sorted([os.path.join(path_to_test_dataset, x) for x in dir_with_test_datasets])\n",
    "\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Отдельный вопрос, какую из построенных моделей использовать для того, чтобы делать предсказания на тест. Можно выбирать лучшую по early_stopping. В таком случае есть риск, что мы подгонимся под валидационную выборку, особенно если она не является очень репрезентативной, однако это самый базовый вариант (используем его). Можно делать разные версии ансамблирования, используя веса с разных эпох. Такой подход требует дополнительного кода (обязательно попробуйте его!). Наконец, можно выбирать такую модель, которая показывает хорошие результаты на валидации и в то же время, не слишком переучена под train выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "best_checkpoint.pt.data-00000-of-00001\tepoch_2_val_0.780.hdf5\nbest_checkpoint.pt.index\t\tepoch_3_val_0.790.hdf5\ncheckpoint\t\t\t\tepoch_4_val_0.792.hdf5\nepoch_10_val_0.801.hdf5\t\t\tepoch_5_val_0.792.hdf5\nepoch_11_val_0.802.hdf5\t\t\tepoch_6_val_0.796.hdf5\nepoch_12_val_0.792.hdf5\t\t\tepoch_7_val_0.800.hdf5\nepoch_13_val_0.799.hdf5\t\t\tepoch_8_val_0.799.hdf5\nepoch_14_val_0.782.hdf5\t\t\tepoch_9_val_0.800.hdf5\nepoch_1_val_0.778.hdf5\n"
     ]
    }
   ],
   "source": [
    "! ls $path_to_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(path_to_checkpoints, 'epoch_11_val_0.802.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = inference(model, dataset_test, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    app_id     score\n",
       "0  1063655  0.028942\n",
       "1  1063672  0.074275\n",
       "2  1063694  0.015878\n",
       "3  1063709  0.088440\n",
       "4  1063715  0.035293"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>app_id</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1063655</td>\n      <td>0.028942</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1063672</td>\n      <td>0.074275</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1063694</td>\n      <td>0.015878</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1063709</td>\n      <td>0.088440</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1063715</td>\n      <td>0.035293</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "test_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds.to_csv('rnn_advanced_baseline_submission.csv', index=None) # ~ 0.760 на public test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}